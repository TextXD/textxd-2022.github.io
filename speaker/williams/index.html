<!doctype html><html lang=en-us><head><meta charset=utf-8><title>Jake Ryland Williams</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="Jake Ryland Williams (Ph.D., Mathematical Sciences) is an Associate Professor of Information Science at Drexel University and a developer of its Graduate Data Science Program. Dr. Williams is PI of the Computational Open Data Exploration and Design (CODED) laboratory, which engineers openly-available, web-based data sets of high scientific value, alongside work on information theoretic foundations that advance the development of machine learning algorithms."><meta name=author content="Textxd"><meta name=generator content="Hugo 0.106.0"><link rel=stylesheet href=https://examplesite.org/plugins/bootstrap/css/bootstrap.min.css><link rel=stylesheet href=https://examplesite.org/plugins/themefisher-font/themefisher-font.min.css><link rel=stylesheet href=https://examplesite.org/scss/style.min.css media=screen><link rel="shortcut icon" href=https://examplesite.org/images/favicon.png type=image/x-icon><link rel=icon href=https://examplesite.org/images/favicon.png type=image/x-icon></head><body><div class=preloader></div><header class=header-bar><nav class="navbar navbar-expand-lg main-nav"><div class=container><a class=navbar-brand href=https://examplesite.org><img src=https://examplesite.org/images/logo.png alt=TextXD class="img-fluid logo-b"></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navigation aria-controls=navigation aria-expanded=false aria-label="Toggle navigation">
<span class=tf-ion-android-menu></span></button><div class="collapse navbar-collapse text-center" id=navigation><ul class="navbar-nav mx-auto"><li class=nav-item><a class=nav-link href=https://examplesite.org>Home</a></li><li class=nav-item><a class=nav-link href=https://examplesite.org/about>About</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Pages</a><div class=dropdown-menu><a class=dropdown-item href=https://examplesite.org/faq>FAQ</a>
<a class=dropdown-item href=https://examplesite.org/schedule>Schedule</a>
<a class=dropdown-item href=https://examplesite.org/pricing>Tickets</a></div></li><li class=nav-item><a class=nav-link href=https://examplesite.org/contact>Contact</a></li></ul></div></div></nav></header><section class=page-header style=background-image:url(https://examplesite.org/images/speakers/Williams.jpg),url(https://examplesite.org/images/bg/cta-bg.jpg)><div class=overly></div><div class=container><div class="row justify-content-center"><div class=col-lg-8><div class="content text-center"><h1 class="mb-3 text-white text-capitalize letter-spacing">Jake Ryland Williams</h1><div class="divider mx-auto mb-4 bg-white"></div><ul class=list-inline><li class=list-inline-item><a href=https://examplesite.org>Home</a> /</li><li class=list-inline-item>Jake Ryland Williams</li></ul></div></div></div></div></section><section class="speaker-single section"><div class=container><div class=row><div class="col-lg-6 col-md-5 mb-5 mb-md-0"><img src=https://examplesite.org/images/speakers/Williams.jpg alt="Jake Ryland Williams" class="img-fluid w-100"></div><div class="col-lg-6 col-md-7"><div class=speaker-single-wrap><div class="speaker-header mb-4"><h2>Jake Ryland Williams</h2><span class=text-color>Drexel University</span></div><h3>How To Train Your Own Transformer From Scratch</h3><p>Few researchers have access to the resources needed to train the state-of-the-art language models (LMs) used in cutting-edge technologies. Processing 'big data' over computational frameworks and expensive GPUs, there are substantial environmental implications: in 2019, one team of researchers estimated that 626,000 pounds of carbon dioxide were produced from the costs associated to producing one model’s parameters (GPT-2's)—the lifetime emissions of approximately five cars. Its developers, OpenAI, reported in 2018 that 'since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time'. After OpenAI released GPT-3 in 2021, a report estimated that by using '10,000 GPUs and 400 gigabits per second of network connectivity per server', the months it took to process '45 Terabytes of text data from all over the internet means that 'GPT-3 could have easily cost 10 or 20 million dollars to train'. Staring down this trend in 2018, OpenAI even suggested: it’s worth preparing for the implications of systems far outside today's capabilities'. We will demonstrate a system intended to fill this profound need with a hyper-efficient, closed-form NLP framework that relieves the costs of developing NLP tools by eliminating the need for backpropagation, and resolves model opacity via interpretable procedures for dimensionality reduction and positional encoding, as well as for pre-training and fine-tuning. Abstracting the salient features of a modern transformer—and methods for parallelized pre-computation of zeroth-order models—our key achievement has been the elimination of backpropagation from training processes: we compute the points towards which gradients descend. Demonstrating this, our prototype—It’s a Machine and Natural Language Model (IaMaN-LM)—applies the closed-form solution to the naïve Bayesian model of co-occurrence: Word2Vec’s softmax-optimized skip-gram objective. As a nuclear engineer may set the dimensions of a charge, our proposed theory sets the parameters of an LM without testing every 'bomb' between a random guess and the target performance. By demonstrating tools released to perform hyper-efficient NLP, we hope to enable developers to leverage limited resources and train their own transformers from scratch, with both sharper resolution and smaller resource requirements. Software will be release in October 2022 here: https://github.com/jakerylandwilliams/IaMaN/</p><p><b>Bio: </b>Jake Ryland Williams (Ph.D., Mathematical Sciences) is an Associate Professor of Information Science at Drexel University and a developer of its Graduate Data Science Program. Dr. Williams is PI of the Computational Open Data Exploration and Design (CODED) laboratory, which engineers openly-available, web-based data sets of high scientific value, alongside work on information theoretic foundations that advance the development of machine learning algorithms.</p><div class=content></div><h5 class="mb-3 mt-5"></h5><ul class="list-inline social-single"></ul></div></div></div></div></section><footer class="footer section"><div class=container><div class="row justify-content-center"><div class="col-lg-6 text-center"><h2 class="text-white mb-3">TextXD</h2><p class=text-white-50>Text Analysis across domains</p><ul class="list-inline footer-socails"></ul></div></div><div class=row><div class="col-lg-12 text-center mt-5"><p class="copy border-top pt-4 text-white-50 mb-0"></p></div></div></div></footer><script>var indexURL="https://examplesite.org/index.json"</script><script src></script>
<script src=https://examplesite.org/plugins/jquery/jquery.js></script>
<script src=https://examplesite.org/plugins/bootstrap/js/bootstrap.min.js></script>
<script src=https://examplesite.org/plugins/syotimer/syotimer.min.js></script>
<script src=https://examplesite.org/plugins/search/fuse.min.js></script>
<script src=https://examplesite.org/plugins/search/mark.js></script>
<script src=https://examplesite.org/plugins/search/search.js></script>
<script src=https://examplesite.org/plugins/google-map/map.js></script>
<script src=https://examplesite.org/js/script.min.js></script></body></html>